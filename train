import os
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import torch

from model import *
from loss import *
from utils import *


import argparse
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    parser.add_argument('--select_loss_type', type=str, default="mse", help='select_loss_type')
    parser.add_argument('--max_patient', type=int, default=10, help='max_patient')
    parser.add_argument('--saveDir', type=str, default="./figures", help='saveDir')
    
    args = parser.parse_args()
    num_epochs = args.num_epochs
    max_patient = args.max_patient
    saveDir = args.saveDir
    if not os.path.exists(saveDir):
        os.makedirs(saveDir)

    epochs = args.epochs
    select_loss_type = args.select_loss_type
    model = DeepCNN(n_kernel=5,kernel_size = 1, n_layer=8)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    
    for epoch in range(epochs):
      i =epoch
      if i > stop_iter:
        stop_iter = 0
        evaluation_interval = 1
        model.eval()
    # for i,batch in enumerate(train_dataset):
      if i%2 == 0 or i>stop_iter:
        X,y,PET_Z = get_supervised_kernel(yy,i)
        current_seed = i
      X_train, y_train = X, y
      idx = np.where(y[0,0,:]==-1)[0][1]
    # for i,batch in enumerate(train_dataset):
      # X_train, y_train,idx = batch
      outputs = model(X_train)
      # outputs = torch.sum(outputs,axis=0)/outputs.shape[0]
      myloss = my_loss(y_train,outputs,select_loss_type)
      loss =  myloss
      # if ratio>best_ratio:
      #   if best_ratio == -999999999999:
      #     best_ratio = ratio
      #     continue
        # print(f"==============ratio < best ratio: {ratio} > {best_ratio}=========, saving model")
        # best_ratio = ratio
        # torch.save(model.state_dict(), '/content/onedrive/ADNI_study2/DL_MKL/saved_model_2_ratio.pth')
      if loss < best_lost:

        # patient = 0

        if best_lost == 999999999999:
          best_lost = loss
          continue
        print(f"***************loss < best loss: {loss} < {best_lost}*****************,saving")
        best_lost = loss

        torch.save(model.state_dict(), f'/content/onedrive/ADNI_study2/DL_MKL/saved_{select_loss_type}.pth')

      if patient > max_patient:
        flag = True
      if flag:
        break
      if i < stop_iter:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
      print(f"i = {i}, loss: {loss},  patient: {patient}, current_seed:{current_seed}, select_loss_type:{select_loss_type}")
      # print(f"i = {len(train_dataset)*(epoch)+i}, loss: {loss}, idx :{idx}, patient: {patient}")

      if i%evaluation_interval == 0:
        print(f"========= Combine ==============")
        acc = classify_kernel(outputs[0,:,:].detach().numpy(),y_train,PET_Z)
        list_modelity = ["GM","MRI", "PET", "CSF", "SNP"]
        modelity_acc =[]
        best_acc = 0
        for j in range(5+1):
            if j<5:
              print(f"========= {list_modelity[j]} ==============")
              acc_i = classify_kernel(X_train.detach().numpy()[j,:,:],y_train,PET_Z)
            else:
              acc_i = classify_kernel( torch.sum(X_train,axis=0).detach().numpy(),y_train,PET_Z)
            if acc_i > best_acc:
              best_acc = acc_i
            modelity_acc.append(acc_i)
        df_result.loc[len(df_result)] =[current_seed]+ modelity_acc + [acc]
        df_result.to_csv(savename,index=False)
        if acc>best_acc:
            print(f"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$ IMPROVE  {acc}>{best_acc} $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$")
            torch.save(model.state_dict(), f'/content/onedrive/ADNI_study2/DL_MKL/saved_{select_loss_type}_best.pth')
            patient = 0
        else:
            patient += 1
        if patient > max_patient:
          flag = True
        if flag:
          break


        plt.figure(figsize=(15,10))
        plt.subplot(3,3,1)
        plt.imshow(outputs.detach().numpy()[0,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{acc*100:.2f}")

        plt.subplot(3,3,3)
        plt.imshow(np.ones(outputs.shape[1:]) - outputs.detach().numpy()[0,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{acc*100:.2f}")

        # ==================
        plt.subplot(3,3,2)
        plt.imshow(y_train.detach().numpy()[0,:,:])
        #===================
        plt.subplot(3,3,4)
        plt.imshow(X_train.detach().numpy()[0,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[0]*100:.2f}")

        plt.subplot(3,3,5)
        plt.imshow(X_train.detach().numpy()[1,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[1]*100:.2f}")

        plt.subplot(3,3,6)
        plt.imshow(X_train.detach().numpy()[2,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[2]*100:.2f}")

        plt.subplot(3,3,7)
        plt.imshow(X_train.detach().numpy()[3,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[3]*100:.2f}")

        plt.subplot(3,3,8)
        plt.imshow(X_train.detach().numpy()[4,:,:])
        plt.xticks([idx], "-")
        plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[4]*100:.2f}")

        plt.subplot(3,3,9)
        plt.imshow( torch.sum(X_train,axis=0).detach().numpy())
        # plt.xticks([idx], "-")
        # plt.yticks([idx], "-")
        plt.title(f"{modelity_acc[5]*100:.2f}")
        plt.suptitle(current_seed)

        plt.savefig(os.path.join(saveDir,f"{current_seed}"))
        plt.show(current_seed)
  #     # Print loss for every epoch
  #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
    # if flag:
    #     break